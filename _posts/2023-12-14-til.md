---
title: 2023-12-14 Apache Airflow
categories: python
---

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">Apache Airflow 入門した<a href="https://t.co/drhUqi3ZDC">https://t.co/drhUqi3ZDC</a></p>&mdash; toshimaru (@toshimaru_e) <a href="https://twitter.com/toshimaru_e/status/1735228061485068414?ref_src=twsrc%5Etfw">December 14, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

## タスク定義例

`>>` 演算子を使い、タスクの依存関係を表現できる。

```python
class Task:
    def __rshift__(self, other):
        print(f"{self.name} followed by {other.name}")
        return other

    def __init__(self, name):
        self.name = name

# Example usage
a = Task('Task A')
b = Task('Task B')
c = Task('Task C')

a >> b >> c
```

## ChatGPT に聞いてみた

> Apache Airflowは、ワークフローのオーケストレーション（自動化とスケジューリング）のためのオープンソースツールです。AirflowはPythonで書かれており、データパイプラインや複雑なワークフローの定義、スケジュール設定、モニタリングを簡単に行うことができます。Airflowの主な特徴として以下の点が挙げられます。
>
> ### キーフィーチャー
>
> 1. **DAG（Directed Acyclic Graph）**: AirflowではワークフローはDAGとして表現されます。DAGはタスクの集合であり、その間の依存関係を定義します。DAG内の各タスクは、データの取得、変換、ロードなどの処理を表します。
> 2. **柔軟なスケジューリング**: タスクは、定期的に実行されるスケジュールに基づいて、または外部イベントに応じてトリガーされるように設定できます。
> 3. **拡張性とカスタマイズ**: Pythonで書かれたカスタムオペレータ、センサ、フックを通じて、Airflowは多くのデータソースやサービスに接続することが可能です。
> 4. **ユーザインターフェース**: AirflowにはウェブベースのUIがあり、DAGのスケジュール設定、実行状況の監視、ログの確認などを行うことができます。
> 5. **スケーラビリティ**: エグゼキュータ（実行機構）の設定により、単一のサーバーから複数のワーカーを持つ大規模なクラスタまで、様々な環境に対応可能です。
>
> ### 使用例
>
> - **データパイプラインの構築**: ETL（Extract, Transform, Load）プロセスを自動化し、データを効率的に処理、変換、データベースにロードします。
> - **機械学習ワークフローの管理**: データの前処理、モデルのトレーニング、評価、デプロイのプロセスを自動化します。
> - **システムのバッチ処理**: 定期的に実行されるバックアップ、レポート生成などのタスクを管理します。
