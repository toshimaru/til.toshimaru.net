---
title: 2023-04-28 AIのハルシネーション
categories: ai
---

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">ChatGPTの息を吸うような嘘、ハルシネーションというらしい » ハルシネーション（Hallucination）とは？：AI・機械学習の用語辞典 - <a href="https://twitter.com/it?ref_src=twsrc%5Etfw">@IT</a> <a href="https://t.co/E4iuj5X9vE">https://t.co/E4iuj5X9vE</a></p>&mdash; toshimaru (@toshimaru_e) <a href="https://twitter.com/toshimaru_e/status/1651435879213445120?ref_src=twsrc%5Etfw">April 27, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

> 主に自然言語処理における「人工知能（AI）のハルシネーション（Hallucination：幻覚）」とは、もっともらしいウソ（＝事実とは異なる内容や、文脈と無関係な内容）の出力が生成されることである

ref. [ハルシネーション（Hallucination）とは？：AI・機械学習の用語辞典 - ＠IT](https://atmarkit.itmedia.co.jp/ait/articles/2303/30/news027.html)

この点、Bing AIは情報のソース表示機能があるのが良いと思った。

> ChatGPTと違うのは、回答の情報のソースとなるリンクが含まれていること。Bing AIはウェブの最新の情報を収集して答えてくれます。リンクに飛ぶと、その情報の出典元のウェブサイトにアクセスすることができるんです。

[Bing AIの使い方。ChatGPTとはここが違う！【4月28日更新】 \| ギズモード・ジャパン](https://www.gizmodo.jp/2023/03/how-to-use-bing-ai-vs-chatgpt.html)
